{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\"><u>This Week Questions</u>\n    \n<p style=\"font-family:cursive;font-size:15px;color:  yellow\"><u>Question 1:</u></p>\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Find a feature with missing values. How many missing values does it have?</li>\n</ul>   \n\n<p style=\"font-family:cursive;font-size:15px;color:  yellow\"><u>Question 2:</u></p>\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>What's the median (50% percentile) for variable 'minimum_nights'?</li>\n</ul>    \n    \n\n<p style=\"font-family:cursive;font-size:15px;color:  yellow\"><u>Question 3:</u></p>\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>We need to deal with missing values for the column from Q1.</li>\n<li>We have two options: fill it with 0 or with the mean of this variable.</li>\n<li>Try both options. For each, train a linear regression model without regularization using the code from the lessons.</li>\n<li>For computing the mean, use the training only!</li>\n<li>Use the validation dataset to evaluate the models and compare the RMSE of each option.</li>\n<li>Round the RMSE scores to 2 decimal digits using round(score, 2)</li>\n<li>Which option gives better RMSE?</li>\n</ul> \n    \n<p style=\"font-family:cursive;font-size:15px;color:  yellow\"><u>Question 4:</u></p>\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Now let's train a regularized linear regression.</li>\n<li>For this question, fill the NAs with 0.</li>\n<li>Try different values of r from this list: [0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10].</li>\n<li>Use RMSE to evaluate the model on the validation dataset.</li>\n<li>Round the RMSE scores to 2 decimal digits.</li>\n<li>Which r gives the best RMSE?</li>\n</ul>    \n    \n    \n<p style=\"font-family:cursive;font-size:15px;color:  yellow\"><u>Question 5:</u></p>\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>We used seed 42 for splitting the data. Let's find out how selecting the seed influences our score.</li>\n<li>Try different seed values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9].</li>\n<li>For each seed, do the train/validation/test split with 60%/20%/20% distribution.</li>\n<li>Fill the missing values with 0 and train a model without regularization.</li>\n<li>For each seed, evaluate the model on the validation dataset and collect the RMSE scores.</li>\n<li>What's the standard deviation of all the scores? To compute the standard deviation, use np.std.</li>\n<li>Round the result to 3 decimal digits (round(std, 3)).</li>\n</ul>     \n    \n<ul style=\"font-family:cursive;font-size:15px;color:  white\">Note: Standard deviation shows how different the values are. If it's low, then all values are approximately the same. If it's high, the values are different. If standard deviation of scores is low, then our model is stable.</ul>    \n\n<p style=\"font-family:cursive;font-size:15px;color:  yellow\"><u>Question 6:</u></p>\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Split the dataset like previously, use seed 9.</li>\n<li>Combine train and validation datasets.</li>\n<li>Fill the missing values with 0 and train a model with r=0.001.</li>\n<li>What's the RMSE on the test dataset?</li>\n</ul>\n\n</div>\n","metadata":{"id":"pEYvPy4MR8XL"}},{"cell_type":"markdown","source":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Importing Libraries</div>","metadata":{"id":"sFHMldcMR8XO"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import mutual_info_score, mean_squared_error\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.linear_model import LogisticRegression, Ridge\n\nplt.rcParams['figure.figsize'] = (16, 8)\nplt.style.use('fivethirtyeight')\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"bfrNH5ZtR8XP","execution":{"iopub.status.busy":"2021-09-27T15:38:19.738073Z","iopub.execute_input":"2021-09-27T15:38:19.739039Z","iopub.status.idle":"2021-09-27T15:38:20.981314Z","shell.execute_reply.started":"2021-09-27T15:38:19.738916Z","shell.execute_reply":"2021-09-27T15:38:20.980115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Loading and Reading Data </div>","metadata":{"id":"6AcmLqEnR8XQ"}},{"cell_type":"code","source":"data = pd.read_csv('../input/new-york-city-airbnb-open-data/AB_NYC_2019.csv')\ndata.head()\n\n","metadata":{"id":"k7Kg5w00R8XR","outputId":"58e0f480-9bd1-4957-b21e-bc8691ccc6c3","execution":{"iopub.status.busy":"2021-09-27T15:38:20.982955Z","iopub.execute_input":"2021-09-27T15:38:20.983251Z","iopub.status.idle":"2021-09-27T15:38:21.341839Z","shell.execute_reply.started":"2021-09-27T15:38:20.98322Z","shell.execute_reply":"2021-09-27T15:38:21.340911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Features used for this Project</div>","metadata":{"id":"LO5YvZUXR8XT"}},{"cell_type":"code","source":"features  = [\n    'neighbourhood_group',\n    'room_type',\n    'latitude',\n    'longitude',\n    'price',\n    'minimum_nights',\n    'number_of_reviews',\n    'reviews_per_month',\n    'calculated_host_listings_count',\n    'availability_365'\n]\ndf = data[features]\n\"\"\"Checking description of this project's data set\"\"\"\ndf.describe()","metadata":{"id":"2_tY-ufER8XU","outputId":"4540c40b-f00a-42c0-8bb2-3ceaabe23c6d","execution":{"iopub.status.busy":"2021-09-27T15:38:21.343217Z","iopub.execute_input":"2021-09-27T15:38:21.343528Z","iopub.status.idle":"2021-09-27T15:38:21.404038Z","shell.execute_reply.started":"2021-09-27T15:38:21.343457Z","shell.execute_reply":"2021-09-27T15:38:21.403212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Missing Values? Impute them with 0</div>","metadata":{"id":"lRNTMkohR8XV"}},{"cell_type":"code","source":"from IPython.display import display\nmissing_vals = df.isnull().sum()\nprint(\"Before Imputing Missing Values\")\ndisplay(missing_vals.to_frame().reset_index().rename({'index': 'Variables', 0: 'Missing Values'}, axis = 1).sort_values(by = 'Missing Values', ascending = False).style.background_gradient('Reds'))\n\n\ndf.fillna(0, inplace = True)\nprint(\"After Imputing Missing Values\")\ndisplay(df.isnull().sum().to_frame().reset_index().rename({'index': 'Variables', 0: 'Missing Values'}, axis = 1).style.background_gradient('Reds'))\n","metadata":{"id":"H2NhQ18ZR8XW","outputId":"f13bfb83-010e-44af-9b6c-6ed74a0b98cc","execution":{"iopub.status.busy":"2021-09-27T15:38:21.405823Z","iopub.execute_input":"2021-09-27T15:38:21.40607Z","iopub.status.idle":"2021-09-27T15:38:21.534365Z","shell.execute_reply.started":"2021-09-27T15:38:21.406042Z","shell.execute_reply":"2021-09-27T15:38:21.533573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:white\">Q1. What is the most frequent observation (mode) for the column 'neighbourhood_group'?</div>","metadata":{"id":"7S9_rm__R8XW"}},{"cell_type":"code","source":"print(\"Mode for variable 'neighbourhood_group': %s\" %(df['neighbourhood_group'].value_counts().head(1)))","metadata":{"id":"1MIBso-xR8XX","outputId":"bd4b3b7d-5c5f-4f45-d9d8-93ba95f08962","execution":{"iopub.status.busy":"2021-09-27T15:38:21.535649Z","iopub.execute_input":"2021-09-27T15:38:21.535869Z","iopub.status.idle":"2021-09-27T15:38:21.549122Z","shell.execute_reply.started":"2021-09-27T15:38:21.535842Z","shell.execute_reply":"2021-09-27T15:38:21.548157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Split the data\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Split your data in train/val/test sets, with 60%/20%/20% distribution.</li>\n<li>Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.</li>\n<li>Make sure that the target value ('price') is not in your dataframe.</li>\n</ul>\n</div>\n","metadata":{"id":"d9zBkFZfR8XX"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\ndf_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\nlen(df_train), len(df_val), len(df_test)\n\ndf_train = df_train.reset_index(drop=True)\ndf_val = df_val.reset_index(drop=True)\ndf_test = df_test.reset_index(drop=True)\n","metadata":{"id":"TDcd-ut6R8XY","execution":{"iopub.status.busy":"2021-09-27T15:38:21.550223Z","iopub.execute_input":"2021-09-27T15:38:21.55051Z","iopub.status.idle":"2021-09-27T15:38:21.57816Z","shell.execute_reply.started":"2021-09-27T15:38:21.550481Z","shell.execute_reply":"2021-09-27T15:38:21.57735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 2:\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Create the correlation matrix for the numerical features of your train dataset. </li>\n<ul>\n<li>In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset. </li>    \n</ul> \n<li>What are the two features that have the biggest correlation in this dataset? </li>   \n    \n</ul> \n</div>\n","metadata":{"execution":{"iopub.status.busy":"2021-09-17T09:24:56.466732Z","iopub.execute_input":"2021-09-17T09:24:56.467046Z","iopub.status.idle":"2021-09-17T09:24:56.527484Z","shell.execute_reply.started":"2021-09-17T09:24:56.467017Z","shell.execute_reply":"2021-09-17T09:24:56.526372Z"},"id":"uUu8RX24R8XY"}},{"cell_type":"code","source":"\"\"\"Creating List of Numerical and Categorical columns\"\"\"\ncategorical = [col for col in df.columns if df[col].dtype == 'object']\nnumerical = [col for col in df.columns if col not in categorical]\n\n\"\"\"Correlation of Numerical Columns\"\"\"\ndisplay(df[numerical].corr())\n\n\"\"\"Heatmap of Numerical Variables\"\"\"\ndisplay(sns.heatmap(df[numerical].corr(), annot = True, lw = 0.2, square = True, cmap = 'crest'))\n","metadata":{"id":"YqfYiZx7R8XZ","outputId":"b80cbf9f-1ec2-4dee-bffb-58536af01e56","execution":{"iopub.status.busy":"2021-09-27T15:38:21.579423Z","iopub.execute_input":"2021-09-27T15:38:21.579663Z","iopub.status.idle":"2021-09-27T15:38:22.430839Z","shell.execute_reply.started":"2021-09-27T15:38:21.579636Z","shell.execute_reply":"2021-09-27T15:38:22.427504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Highest Correlation is between\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>reviews_per_month and number_of_reviews: 0.589407</li>\n</ul>\n</div>","metadata":{"id":"hPZj64Lucz7s"}},{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Make price binary\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>We need to turn the price variable from numeric into binary.</li>\n<li>Let's create a variable above_average which is 1 if the price is above (or equal to) 152.</li>\n</ul>\n</div>","metadata":{"id":"2Tg0JxEDZeWW"}},{"cell_type":"code","source":"\"\"\"price variable from numeric into binary.\"\"\"\ndf_full_train['above_average'] = (df_full_train['price'] >= 152).values.astype(int)\n","metadata":{"id":"1ya3UedmR8XZ","execution":{"iopub.status.busy":"2021-09-27T15:38:22.434711Z","iopub.execute_input":"2021-09-27T15:38:22.434991Z","iopub.status.idle":"2021-09-27T15:38:22.442535Z","shell.execute_reply.started":"2021-09-27T15:38:22.434958Z","shell.execute_reply":"2021-09-27T15:38:22.441625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 3:\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Calculate the mutual information score with the (binarized) price for the two categorical variables that we have. Use the training set only.</li>\n<li>Which of these two variables has bigger score?</li>\n<li>Round it to 2 decimal digits using round(score, 2)</li>\n</ul> \n</div>\n","metadata":{"execution":{"iopub.status.busy":"2021-09-17T10:32:33.230859Z","iopub.execute_input":"2021-09-17T10:32:33.231261Z","iopub.status.idle":"2021-09-17T10:32:33.25253Z","shell.execute_reply.started":"2021-09-17T10:32:33.231221Z","shell.execute_reply":"2021-09-17T10:32:33.25177Z"},"id":"2XGgZimiR8Xa"}},{"cell_type":"code","source":"\"\"\"Mutual Information\"\"\"\ndef mutual_info_bin_score(series):\n    return mutual_info_score(series, df_full_train.above_average)\n\nmi = df_full_train[categorical].apply(mutual_info_bin_score)\nmi.round(2).sort_values(ascending=False)    ","metadata":{"id":"9P0OJjcdR8Xa","outputId":"b383b1d6-bfae-4e25-ce7d-32f2596d24ce","execution":{"iopub.status.busy":"2021-09-27T15:38:22.444029Z","iopub.execute_input":"2021-09-27T15:38:22.444407Z","iopub.status.idle":"2021-09-27T15:38:22.57161Z","shell.execute_reply.started":"2021-09-27T15:38:22.444359Z","shell.execute_reply":"2021-09-27T15:38:22.570679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:white\">Variable room_type has the biggest score = 0.14</div>","metadata":{"id":"5msozvRpfCcE"}},{"cell_type":"markdown","source":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 4:\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Now let's train a logistic regression</li>\n<li>Remember that we have two categorical variables in the data. Include them using one-hot encoding.</li>\n<li>Fit the model on the training dataset.</li>\n<ul>\n<li>To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:</li> \n<li>model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42)</li>\n</ul>     \n<li>Calculate the accuracy on the validation dataset and rount it to 2 decimal digits.</li>\n</ul> \n</div>","metadata":{"id":"dbh2u7IjR8Xb"}},{"cell_type":"code","source":"\"\"\"Taking Care of Categorical variables\"\"\"\ny_train = (df_train['price'] >= 152).values.astype(int)\ny_val = (df_val['price'] >= 152).values.astype(int)\ny_test = (df_test['price'] >= 152).values.astype(int)\n\ndel df_train['price']\ndel df_val['price']\ndel df_test['price']\n\nnumerical.remove('price')\n\ndecision = (y_val >= 152).astype(int)\n","metadata":{"id":"lnbwycjcR8Xb","execution":{"iopub.status.busy":"2021-09-27T15:38:22.574092Z","iopub.execute_input":"2021-09-27T15:38:22.574464Z","iopub.status.idle":"2021-09-27T15:38:22.744101Z","shell.execute_reply.started":"2021-09-27T15:38:22.574423Z","shell.execute_reply":"2021-09-27T15:38:22.74315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_accuracy(features):\n    # one-hot encoding datasets\n    dv = DictVectorizer(sparse=False)\n\n    train_dict = df_train[features].to_dict(orient='records')\n    val_dict = df_val[features].to_dict(orient='records')\n\n    X_train = dv.fit_transform(train_dict)\n    X_val = dv.transform(val_dict)\n\n    \"\"\"Fitting the Model on Training Set\"\"\"\n    model = LogisticRegression(solver='liblinear', C=1.0, random_state=42)\n    model.fit(X_train, y_train)\n\n    \"\"\"Using the model on validation\"\"\"\n    y_pred = model.predict_proba(X_val)[:,1]\n\n    \"\"\"Setting up Decision Threshold to 0.5\"\"\"\n    decision = (y_pred >= 0.5)\n\n    \"\"\"Calculating accuracy\"\"\"\n    accuracy = (y_val == decision).mean()\n    \n\n    df_pred = pd.DataFrame()\n    df_pred['probability'] = y_pred\n    df_pred['prediction'] = decision\n    df_pred['actual'] = y_val\n    df_pred['correct'] = df_pred.prediction == df_pred.actual\n    return accuracy, df_pred\nacc, df_pred = calculate_accuracy(numerical+categorical)    \n\nprint(acc)\ndf_pred.head()","metadata":{"id":"M6oodqw1nP4z","outputId":"10a605af-22ff-4a44-f858-08b43b045f59","execution":{"iopub.status.busy":"2021-09-27T15:38:22.74558Z","iopub.execute_input":"2021-09-27T15:38:22.745861Z","iopub.status.idle":"2021-09-27T15:38:23.967833Z","shell.execute_reply.started":"2021-09-27T15:38:22.745821Z","shell.execute_reply":"2021-09-27T15:38:23.966753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_vars_accuracy,_ = calculate_accuracy(numerical+categorical)\nall_vars_accuracy.round(2)","metadata":{"id":"44WxOW65-ZCs","outputId":"4a032839-add3-4286-95a6-39df08c6a141","execution":{"iopub.status.busy":"2021-09-27T15:38:23.973373Z","iopub.execute_input":"2021-09-27T15:38:23.976096Z","iopub.status.idle":"2021-09-27T15:38:25.185767Z","shell.execute_reply.started":"2021-09-27T15:38:23.976027Z","shell.execute_reply":"2021-09-27T15:38:25.184843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 5:\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>We have 9 features: 7 numerical features and 2 categorical.</li>\n<li>Let's find the least useful one using the feature elimination technique.</li>\n<li>Train a model with all these features (using the same parameters as in Q4).</li>\n<li>Now exclude each feature from this set and train a model without it. Record the accuracy for each model.</li>\n<li>For each feature, calculate the difference between the original accuracy and the accuracy without the feature.</li>\n<li>Which of following feature has the smallest difference? </li>\n<ul>\n<li>neighbourhood_group</li> \n<li>room_type</li>\n<li>number_of_reviews</li> \n<li>reviews_per_month</li>\n</ul> \n</ul>\n</div>\n","metadata":{"id":"QQj9ehf8R8Xb"}},{"cell_type":"code","source":"useful_features = numerical + categorical\ndiff = {}\nfor i in useful_features:\n  features = useful_features.copy()\n  features.remove(i)\n  acc,_ = calculate_accuracy(features)\n  diff[\"Difference in accuracy when removing %s\"%i] = all_vars_accuracy - acc\n\ndiff","metadata":{"id":"7FP2tjp6zb70","outputId":"eb668e68-0973-4be1-87e8-3cd963617e06","execution":{"iopub.status.busy":"2021-09-27T15:38:25.191063Z","iopub.execute_input":"2021-09-27T15:38:25.193676Z","iopub.status.idle":"2021-09-27T15:38:34.888391Z","shell.execute_reply.started":"2021-09-27T15:38:25.193619Z","shell.execute_reply":"2021-09-27T15:38:34.887388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(diff.values(), index = diff.keys()).rename({0: 'differences'}, axis = 1).sort_values(by = 'differences', ascending = True).style.background_gradient('Reds')","metadata":{"id":"NO3t4J5nR8Xb","outputId":"336992df-6d2d-450e-a9f0-5c251feb45ea","execution":{"iopub.status.busy":"2021-09-27T15:38:34.894329Z","iopub.execute_input":"2021-09-27T15:38:34.897138Z","iopub.status.idle":"2021-09-27T15:38:34.926872Z","shell.execute_reply.started":"2021-09-27T15:38:34.897071Z","shell.execute_reply":"2021-09-27T15:38:34.925873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Smallest Difference:\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>number_of_reviews (0.000895)</li> \n</ul></div>","metadata":{"id":"BtCfpXQpUyG1"}},{"cell_type":"markdown","source":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 6:\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>For this question, we'll see how to use a linear regression model from Scikit-Learn</li>\n<li>We'll need to use the original column 'price'. Apply the logarithmic transformation to this column.</li>\n<li>Fit the Ridge regression model on the training data.</li>\n<li>This model has a parameter alpha. Let's try the following values: [0, 0.01, 0.1, 1, 10]</li>\n<li>Which of these alphas leads to the best RMSE on the validation set? Round your RMSE scores to 3 decimal digits.</li>\n</ul>\n</div>\n","metadata":{"id":"Mx817--5FAEz"}},{"cell_type":"code","source":"\"\"\"Preparing Data for Linear Regression with Price Variable included\"\"\"\ndf_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\ndf_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\nlen(df_train), len(df_val), len(df_test)\n\ndf_train = df_train.reset_index(drop=True)\ndf_val = df_val.reset_index(drop=True)\ndf_test = df_test.reset_index(drop=True)\n\n\"\"\"Creating List of Numerical and Categorical columns\"\"\"\ncategorical = [col for col in df.columns if df[col].dtype == 'object']\nnumerical = [col for col in df.columns if col not in categorical]\n\n\"\"\"Apply the log transformation to the price variable using the np.log1p() function.\"\"\"\ny_train = np.log1p(df_train['price'].values)\ny_val = np.log1p(df_val['price'].values)\ny_test = np.log1p(df_test['price'].values)\n\n\n\"\"\"Make sure that the target value ('price') is not in your dataframe.\"\"\"\ndel df_train['price']\ndel df_val['price']\ndel df_test['price']\n\n\"\"\"Taking care of Categorical Variables\"\"\"\ndv = DictVectorizer(sparse=False)\nfeatures = categorical + numerical\nfeatures.remove('price')\ntrain_dict = df_train[features].to_dict(orient='records')\nval_dict = df_val[features].to_dict(orient='records')\n\nX_train = dv.fit_transform(train_dict)\nX_val = dv.transform(val_dict)","metadata":{"id":"aCbCagCZFGCm","execution":{"iopub.status.busy":"2021-09-27T15:47:07.312919Z","iopub.execute_input":"2021-09-27T15:47:07.31433Z","iopub.status.idle":"2021-09-27T15:47:08.234239Z","shell.execute_reply.started":"2021-09-27T15:47:07.314255Z","shell.execute_reply":"2021-09-27T15:47:08.233618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = {}\nfor alpha in [0, 0.01, 0.1, 1, 10]:\n    model = Ridge(alpha=alpha, random_state= 42)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_val)\n    score = np.sqrt(mean_squared_error(y_val, y_pred))\n    scores[alpha] = score.round(3)\n    print(\"RMSE with alpha = %s and not rounding to 3 digits: %s\"%(alpha, score) )\nprint(\" \\nRMSE with rounding off to 3 digits\")\nprint(scores)\n\n","metadata":{"id":"g_BQFgFqFfNa","outputId":"ec9ef0b8-c4e8-4caf-faf6-70994768d41e","execution":{"iopub.status.busy":"2021-09-27T15:47:08.235502Z","iopub.execute_input":"2021-09-27T15:47:08.236356Z","iopub.status.idle":"2021-09-27T15:47:08.327675Z","shell.execute_reply.started":"2021-09-27T15:47:08.236321Z","shell.execute_reply":"2021-09-27T15:47:08.32678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Table of RMSE rounded to 3 digits\")\npd.DataFrame(scores.values(), index = scores.keys()).rename({0: 'RMSE'}, axis = 1).sort_values(by = 'RMSE', ascending = True).style.background_gradient('Reds')","metadata":{"id":"E3cz3PzdFlPy","outputId":"cec75c11-1dc6-47bd-f497-3173e8151945","execution":{"iopub.status.busy":"2021-09-27T15:47:08.482516Z","iopub.execute_input":"2021-09-27T15:47:08.4828Z","iopub.status.idle":"2021-09-27T15:47:08.502683Z","shell.execute_reply.started":"2021-09-27T15:47:08.482772Z","shell.execute_reply":"2021-09-27T15:47:08.501974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:white\">$ \\large alpha$ that leads to the best RMSE: 0</div>","metadata":{"id":"ASMloPTwVTnU"}}]}