{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\"><u>Homework 4</u>    \n<p style=\"font-family:cursive;font-size:17px; color:white\" > \n<a style=\"font-family:cursive;font-size:17px; color: yellow\" href=\"https://datatalks.club/courses/2021-winter-ml-zoomcamp.html\" target=\"_blank\"> <u>Link for the Course</u></a></p>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1\">A. Preapartion for assignment</a></li>    \n<ul>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1.1\">Importing Data</a></li>   \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1.2\">2. Code to de-code encoded numbers</a></li> \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1.3\">3. Prepare the numerical variables </a></li>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1.4\"> 4. Remove clients with unknown default status  </a></li> \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1.5\"> 5. Create the target variable  </a></li>  \n    </ul>\n\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#2\"> B.  Questions</a></li>    \n</div>    ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score, auc\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.metrics import recall_score, precision_score\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-04T10:58:21.65184Z","iopub.execute_input":"2021-10-04T10:58:21.652127Z","iopub.status.idle":"2021-10-04T10:58:21.65985Z","shell.execute_reply.started":"2021-10-04T10:58:21.652099Z","shell.execute_reply":"2021-10-04T10:58:21.659048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv","metadata":{"execution":{"iopub.status.busy":"2021-10-04T10:25:55.385828Z","iopub.execute_input":"2021-10-04T10:25:55.38624Z","iopub.status.idle":"2021-10-04T10:25:56.452432Z","shell.execute_reply.started":"2021-10-04T10:25:55.386208Z","shell.execute_reply":"2021-10-04T10:25:56.451344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('CreditScoring.csv')\ndf.columns = df.columns.str.lower()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T10:25:56.456197Z","iopub.execute_input":"2021-10-04T10:25:56.456468Z","iopub.status.idle":"2021-10-04T10:25:56.475724Z","shell.execute_reply.started":"2021-10-04T10:25:56.45643Z","shell.execute_reply":"2021-10-04T10:25:56.474839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"status_values = {\n    1: 'ok',\n    2: 'default',\n    0: 'unk'\n}\n\ndf.status = df.status.map(status_values)\n\n\nhome_values = {\n    1: 'rent',\n    2: 'owner',\n    3: 'private',\n    4: 'ignore',\n    5: 'parents',\n    6: 'other',\n    0: 'unk'\n}\n\ndf.home = df.home.map(home_values)\n\nmarital_values = {\n    1: 'single',\n    2: 'married',\n    3: 'widow',\n    4: 'separated',\n    5: 'divorced',\n    0: 'unk'\n}\n\ndf.marital = df.marital.map(marital_values)\n\nrecords_values = {\n    1: 'no',\n    2: 'yes',\n    0: 'unk'\n}\n\ndf.records = df.records.map(records_values)\n\njob_values = {\n    1: 'fixed',\n    2: 'partime',\n    3: 'freelance',\n    4: 'others',\n    0: 'unk'\n}\n\ndf.job = df.job.map(job_values)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T10:25:56.477328Z","iopub.execute_input":"2021-10-04T10:25:56.47762Z","iopub.status.idle":"2021-10-04T10:25:56.503796Z","shell.execute_reply.started":"2021-10-04T10:25:56.477582Z","shell.execute_reply":"2021-10-04T10:25:56.502944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for c in ['income', 'assets', 'debt']:\n    df[c] = df[c].replace(to_replace=99999999, value=0)\ndf = df[df.status != 'unk'].reset_index(drop=True)\ndf['default'] = (df.status == 'default').astype(int)\ndel df['status']","metadata":{"execution":{"iopub.status.busy":"2021-10-04T10:25:56.506237Z","iopub.execute_input":"2021-10-04T10:25:56.506782Z","iopub.status.idle":"2021-10-04T10:25:56.520671Z","shell.execute_reply.started":"2021-10-04T10:25:56.506733Z","shell.execute_reply":"2021-10-04T10:25:56.519562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n\n\n\n<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Your code\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n    <li>What are the categorical variables? What are the numerical?</li>    \n</ul> \n</div>\n\n","metadata":{}},{"cell_type":"code","source":"categorical = [col for col in df.columns if df[col].dtypes == 'object']\nnumerical = [col for col in df.columns if col not in categorical]\nprint(\"Numerical Columns: \", numerical)\nprint(\"Categorical Columns: \", categorical)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T10:25:56.521789Z","iopub.execute_input":"2021-10-04T10:25:56.522029Z","iopub.status.idle":"2021-10-04T10:25:56.530329Z","shell.execute_reply.started":"2021-10-04T10:25:56.522001Z","shell.execute_reply":"2021-10-04T10:25:56.529221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Task\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use train_test_split funciton for that with random_state=1</li>\n \n</ul> \n</div>\n","metadata":{"execution":{"iopub.status.busy":"2021-10-01T13:53:33.274732Z","iopub.execute_input":"2021-10-01T13:53:33.275045Z","iopub.status.idle":"2021-10-01T13:53:33.28258Z","shell.execute_reply.started":"2021-10-01T13:53:33.275013Z","shell.execute_reply":"2021-10-01T13:53:33.281781Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf_full_train, df_test = train_test_split(df, test_size = 0.2, random_state = 1)\ndf_train, df_valid = train_test_split(df_full_train, test_size = 0.25, random_state = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T10:25:56.531586Z","iopub.execute_input":"2021-10-04T10:25:56.532167Z","iopub.status.idle":"2021-10-04T10:25:56.714945Z","shell.execute_reply.started":"2021-10-04T10:25:56.53208Z","shell.execute_reply":"2021-10-04T10:25:56.71426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_train) / len(df)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T10:25:56.716043Z","iopub.execute_input":"2021-10-04T10:25:56.716563Z","iopub.status.idle":"2021-10-04T10:25:56.724912Z","shell.execute_reply.started":"2021-10-04T10:25:56.716528Z","shell.execute_reply":"2021-10-04T10:25:56.724026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 1:\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>ROC AUC could also be used to evaluate feature importance of numerical variables. Let's do that</li>\n<ul>\n<li>For each numerical variable, use it as score and compute AUC with the \"default\" variable</li> \n<li> Use the training dataset for that</li> \n    \n   \n</ul> \n<li>If your AUC is greater than 0.5, invert this variable by putting \"-\" in front</li>   \n<li>(e.g. -df_train['expenses'])</li> \n<li>AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.If your AUC is greater than 0.5, invert this variable by putting \"-\" in front</li>      \n</ul> \n</div>","metadata":{}},{"cell_type":"code","source":"for col in numerical:\n    auc_score = roc_auc_score(df_train.default, df_train[col])\n    if auc_score < 0.5:\n        auc_score = roc_auc_score(df_train.default, -df_train[col])\n    print(f'{col: <10}: {auc_score: .4f}')   ","metadata":{"execution":{"iopub.status.busy":"2021-10-04T11:02:17.525324Z","iopub.execute_input":"2021-10-04T11:02:17.526344Z","iopub.status.idle":"2021-10-04T11:02:17.562454Z","shell.execute_reply.started":"2021-10-04T11:02:17.5263Z","shell.execute_reply":"2021-10-04T11:02:17.561824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Training the model. From now on, use these columns only: ['seniority', 'income', 'assets', 'records', 'job', 'home']\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:</li>\n<li>LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)</li>\n\n</ul> \n</div>","metadata":{}},{"cell_type":"code","source":"features = ['seniority', 'income', 'assets', 'records', 'job', 'home']\n\n\"\"\"one-hot encoding datasets\"\"\"\ndv = DictVectorizer()\ntrain_dict = df_train[features].to_dict(orient = 'records')\nval_dict = df_valid[features].to_dict(orient = 'records')\n\n\"\"\"Creating X_train, y_train, \"\"\"\nX_train = dv.fit_transform(train_dict)\nX_val = dv.transform(val_dict)\ny_train = df_train['default'].values\ny_valid = df_valid['default'].values\n\n\"\"\"Fitting the Model on Training Set\"\"\"\nmodel = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\nmodel.fit(X_train, y_train)\npredictions = model.predict_proba(X_val)[:, 1]\n\n\"\"\"AUC for this model\"\"\"\nauc_score = roc_auc_score(y_valid, predictions)\nprint(\"Answer 2: AUC of the model %s\" %round(auc_score, 3))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T11:01:43.51413Z","iopub.execute_input":"2021-10-04T11:01:43.514387Z","iopub.status.idle":"2021-10-04T11:01:43.601779Z","shell.execute_reply.started":"2021-10-04T11:01:43.514362Z","shell.execute_reply":"2021-10-04T11:01:43.600945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 3\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Now let's compute precision and recall for our model.</li>\n<ul>\n<li>Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01</li>\n<li>For each threshold, compute precision and recall</li>\n<li>Plot them</li>\n</ul>\n</ul> \n</div>","metadata":{}},{"cell_type":"code","source":"# function to get Precision and Recall scores for a given range of thresholds\n\ndef precision_recall_dataframe(y_val, y_pred, thresholds):\n    scores = []\n\n    for t in thresholds:\n        actual_positive = (y_val == 1)\n        actual_negative = (y_val == 0)\n\n        predict_positive = (y_pred >= t)\n        predict_negative = (y_pred < t)\n\n        tp = (predict_positive & actual_positive).sum()\n        tn = (predict_negative & actual_negative).sum()\n\n        fp = (predict_positive & actual_negative).sum()\n        fn = (predict_negative & actual_positive).sum()\n\n        scores.append((t, tp, fp, fn, tn))\n\n    columns = ['threshold', 'tp', 'fp', 'fn', 'tn']\n    df_scores = pd.DataFrame(scores, columns=columns)\n\n    df_scores['precision'] = df_scores.tp / (df_scores.tp + df_scores.fp)  \n    df_scores['recall'] = df_scores.tp / (df_scores.tp + df_scores.fn) \n        \n        \n    df_scores['tpr'] = df_scores.tp / (df_scores.tp + df_scores.fn)\n    df_scores['fpr'] = df_scores.fp / (df_scores.fp + df_scores.tn)\n    return df_scores[['threshold','precision', 'recall']]\n\n\"\"\"Calculating Precision and Recall for various thresholds\"\"\"\nth = np.arange(0, 1.01, 0.01)\ndf_scores = precision_recall_dataframe(y_valid, predictions, th)\n\n\"\"\"Plotting the data\"\"\"\nplt.plot(df_scores[['precision', 'recall']])\nplt.xlabel('Threshold')\nplt.title('Precision-Recall curves')\nplt.grid()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-04T11:53:37.419179Z","iopub.execute_input":"2021-10-04T11:53:37.420074Z","iopub.status.idle":"2021-10-04T11:53:37.60337Z","shell.execute_reply.started":"2021-10-04T11:53:37.420029Z","shell.execute_reply":"2021-10-04T11:53:37.602664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 4\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both.</li>\n<ul>\n<li>This is the formula for computing F1:</li>\n<li>$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$</li>\n<li>Where $P$ is precision and $R$ is recall.</li>\n<li>Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01</li>\n</ul>\n</ul> \n</div>","metadata":{}},{"cell_type":"code","source":"df_scores['f1'] = 2 * (df_scores.precision * df_scores.recall)/(df_scores.precision + df_scores.recall)\ndf_scores[df_scores['f1'] == max(df_scores['f1'])]","metadata":{"execution":{"iopub.status.busy":"2021-10-04T11:56:53.217869Z","iopub.execute_input":"2021-10-04T11:56:53.218137Z","iopub.status.idle":"2021-10-04T11:56:53.230955Z","shell.execute_reply.started":"2021-10-04T11:56:53.218111Z","shell.execute_reply":"2021-10-04T11:56:53.230215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 5\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds:</li>\n<ul>\n<li>KFold(n_splits=5, shuffle=True, random_state=1)</li>\n<li>Iterate over different folds of df_full_train</li>\n<li>Split the data into train and validation</li>\n<li>Train the model on train with these parameters: LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)</li>\n<li>Use AUC to evaluate the model on validation</li>\n</ul>\n</ul> \n</div>","metadata":{"execution":{"iopub.status.busy":"2021-10-04T11:57:34.373006Z","iopub.execute_input":"2021-10-04T11:57:34.37359Z","iopub.status.idle":"2021-10-04T11:57:34.380743Z","shell.execute_reply.started":"2021-10-04T11:57:34.373556Z","shell.execute_reply":"2021-10-04T11:57:34.379972Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\nscores = []\n\n\"\"\"Using KFold from sklearn\"\"\"\nkfold = KFold(n_splits=5, shuffle=True, random_state=1)\n\n\"\"\"Iterate over different folds of full_train\"\"\"\nfor fold, (train_idx, val_idx) in enumerate(kfold.split(df_full_train)):\n        \n        \"\"\"Split the data into train and validation\"\"\"\n        df_train = df_full_train.iloc[train_idx]\n        df_valid = df_full_train.iloc[val_idx]\n\n        y_train = df_train.default.values\n        y_valid = df_valid.default.values\n        \n        \"\"\"Apply one-hot-encoding using DictVectorizer\"\"\"\n        train_dict = df_train[features].to_dict(orient='records')\n        val_dict = df_valid[features].to_dict(orient='records')\n        \n        dv = DictVectorizer(sparse=False)\n\n        X_train = dv.fit_transform(train_dict)\n        X_val = dv.transform(val_dict)\n        \n        # Train Logistic regression on train part\n        model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n        model.fit(X_train, y_train)\n\n        # Use AUC to evaluate the model on validation part\n        y_pred = model.predict_proba(X_val)[:, 1]\n        auc = roc_auc_score(y_valid, y_pred)\n        \n        # save fold score\n        scores.append(auc)\n\n        print('fold %s roc-auc score: %s' %(fold, auc))\n\nprint(\"\\n Standard Deviation of Scores: %s\" %np.std(scores).round(3))        ","metadata":{"execution":{"iopub.status.busy":"2021-10-04T12:08:44.731398Z","iopub.execute_input":"2021-10-04T12:08:44.731866Z","iopub.status.idle":"2021-10-04T12:08:45.353804Z","shell.execute_reply.started":"2021-10-04T12:08:44.731829Z","shell.execute_reply":"2021-10-04T12:08:45.353022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 6\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Now let's use 5-Fold cross-validation to find the best parameter C</li>\n<ul>\n<li>Iterate over the following C values: [0.01, 0.1, 1, 10]</li>\n<li>Use these parametes for the model: LogisticRegression(solver='liblinear', C=C, max_iter=1000)</li>\n<li>Compute the mean score as well as the std</li>\n</ul>\n</ul> \n</div>","metadata":{}},{"cell_type":"code","source":"scores = list()\n\"\"\"C Values\"\"\"\nC_values = [0.01, 0.1, 1, 10]\n\nkfold = KFold(n_splits=5, shuffle=True, random_state = 1)\n\n\"\"\"Iterate over the C values\"\"\"\nfor C in C_values:\n    kfold_scores = list()\n    \"\"\"Iterate over different folds of df_full_train\"\"\"\n    for train_idx, val_idx in kfold.split(df_full_train):\n            \n            df_train = df_full_train.iloc[train_idx, :]\n            df_val = df_full_train.iloc[val_idx, :]\n\n            y_train = df_train.default.values\n            y_val = df_val.default.values\n\n            train_dict = df_train[features].to_dict(orient='records')\n            val_dict = df_val[features].to_dict(orient='records')\n        \n            dv = DictVectorizer(sparse=False)\n        \n            X_train = dv.fit_transform(train_dict)\n            X_val = dv.transform(val_dict)\n\n            model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n            model.fit(X_train, y_train)\n\n            y_pred = model.predict_proba(X_val)[:, 1]\n            auc = roc_auc_score(y_val, y_pred)\n            \n            kfold_scores.append(auc)\n    \n    \"\"\"compute the mean and std of scores\"\"\"\n    mean_auc = np.mean(kfold_scores)\n    std = np.std(kfold_scores)\n    \n    \"\"\"save mean auc and std of current C value\"\"\"\n    kfold_scores.extend([mean_auc, std])\n    scores.append(kfold_scores)\n    \n    print(f'C={C:<5} average roc-auc: {mean_auc:.4f} +/- {std:.3f}')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T12:25:07.921763Z","iopub.execute_input":"2021-10-04T12:25:07.922491Z","iopub.status.idle":"2021-10-04T12:25:10.572998Z","shell.execute_reply.started":"2021-10-04T12:25:07.922442Z","shell.execute_reply":"2021-10-04T12:25:10.570348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_AUC = pd.DataFrame(scores, columns = ['fold_1', 'fold_2', 'fold_3', 'fold_4', \n                                        'fold_5', 'mean_auc', 'std'], \n            index=[str(c) for c in C_values]).rename_axis('C')\n\ndf_AUC[df_AUC['mean_auc'] == max(df_AUC['mean_auc'])].reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T12:27:19.954645Z","iopub.execute_input":"2021-10-04T12:27:19.955436Z","iopub.status.idle":"2021-10-04T12:27:19.972991Z","shell.execute_reply.started":"2021-10-04T12:27:19.95538Z","shell.execute_reply":"2021-10-04T12:27:19.972191Z"},"trusted":true},"execution_count":null,"outputs":[]}]}