{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"table-of-contents\"></a>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\"><u>Chapter 3</u></div>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\"><u>Classification</u>    \n<p style=\"font-family:cursive;font-size:17px; color:white\" >Notebook is a part of FREE ML course by Glexey Grigorev. \n<a style=\"font-family:cursive;font-size:17px; color: yellow\" href=\"https://datatalks.club/courses/2021-winter-ml-zoomcamp.html\" target=\"_blank\"> <u>Link for the Course</u></a></p>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1\"> 1. Introduction </a></li>      \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#2\" target=\"_blank\"> 2. Impoting Libraries </a></li> \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15;\" href = \"#3\"> 3. Loading and Reading Data </a></li> \n<li  style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#4\"> 4. Cleaning Strings in Column and Values</a></li> \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#5\"> 5. Data Preparation </a></li>  \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#6\"> 6. Setting up Validation Framework </a></li>  \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#7\"> 7. Exploratory Data Analysis  </a></li>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#8.1\"> 8. Feature Importance </a></li>\n    <ul> \n    <li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#8.1\"> 8.1 Feature Importance: Churn Rate and Risk Ratio</a></li> \n    <li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#8.2\"> 8.2 Feature Importance: Mutual Information </a></li> \n    <li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#8.3\">  8.3 Feature Importance: Correlation</a></li>\n </ul>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#9\"> 9. One Hot Encoding using DictVectorizer </a></li>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#10\"> 10. Logistic Regression</a></li>     \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#11\"> 11. Training logistic regression with Scikit-Learn</a></li> \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#12\"> 12. Model interpretation</a></li>  \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#13\"> 13. Using the model </a></li>  \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#14\"> 14. Summary</a></li>    \n           \n  \n</div>\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\"><u>Chapter 4</u></div>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\"><u>Evaluation</u>    \n<p style=\"font-family:cursive;font-size:17px; color:white\" >Notebook is a part of FREE ML course by Glexey Grigorev\n<a style=\"font-family:cursive;font-size:17px; color: yellow\" href=\"https://datatalks.club/courses/2021-winter-ml-zoomcamp.html\" target=\"_blank\"> <u>Link for the Course</u></a></p>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1\"> 1. Evaluation metrics: session overview  </a></li>   \n  \n</div>    ","metadata":{}},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"1\"></a>\n\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:yellow\">1. Introduction\n<p style=\"font-family:cursive;font-size:17px;color:white\"><u>Context</u>: Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\" [IBM Sample Data Sets]</p>\n<p style=\"font-family:cursive;font-size:17px;color:white\"><u>Content</u>: Each row represents a customer, each column contains customer’s attributes described on the column Metadata.</p>   \n<ul style=\"font-family:cursive;font-size:17px;color:white\">The data set includes information about:\n<li> Customers who left within the last month – the column is called Churn</li>\n<li > Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies</li>\n    <li >Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges</li>\n    <li>Demographic info about customers – gender, age range, and if they have partners and dependents</li></ul>\n    \n    \n<p style=\"font-family:cursive;font-size:17px;color:white\"><p style=\"font-family:cursive;font-size:17px; color:white\" >\n<a style=\"font-family:cursive;font-size:17px; color: yellow\" href=\"https://www.kaggle.com/blastchar/telco-customer-churn\" target=\"_blank\"> <u>Dataset in Kaggle</u></a></p>\n<p style=\"font-family:cursive;font-size:17px; color:white\" >\n<a style=\"font-family:cursive;font-size:17px; color: yellow\" href=\"https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-03-churn-prediction/WA_Fn-UseC_-Telco-Customer-Churn.csv\" target=\"_blank\"> <u>GitHub Repository</u></a></p>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"2\"></a>\n\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">2. Importing Libraries\n    \n</div>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams['figure.figsize'] = (16, 8)\nplt.style.use('fivethirtyeight')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:11.387092Z","iopub.execute_input":"2021-09-23T10:35:11.38738Z","iopub.status.idle":"2021-09-23T10:35:11.54473Z","shell.execute_reply.started":"2021-09-23T10:35:11.38735Z","shell.execute_reply":"2021-09-23T10:35:11.54404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"3\"></a>\n\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">3. Loading and Reading Data\n    \n</div>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:11.546068Z","iopub.execute_input":"2021-09-23T10:35:11.546436Z","iopub.status.idle":"2021-09-23T10:35:11.662853Z","shell.execute_reply.started":"2021-09-23T10:35:11.546405Z","shell.execute_reply":"2021-09-23T10:35:11.662095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"4\"></a>\n\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">4. Data Cleaning: Cleaning Strings in Column and values\n    \n</div>","metadata":{}},{"cell_type":"code","source":"df.columns = df.columns.str.lower().str.replace(' ', '_')\n\ncategorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n\nfor c in categorical_columns:\n    df[c] = df[c].str.lower().str.replace(' ', '_')\n    \ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:11.663979Z","iopub.execute_input":"2021-09-23T10:35:11.664663Z","iopub.status.idle":"2021-09-23T10:35:11.872815Z","shell.execute_reply.started":"2021-09-23T10:35:11.664597Z","shell.execute_reply":"2021-09-23T10:35:11.872201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"5\"></a>\n\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">5. Data Preparation\n    \n</div>","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T13:35:46.806264Z","iopub.execute_input":"2021-09-24T13:35:46.806935Z","iopub.status.idle":"2021-09-24T13:35:46.89072Z","shell.execute_reply.started":"2021-09-24T13:35:46.80682Z","shell.execute_reply":"2021-09-24T13:35:46.889666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['totalcharges'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:11.913626Z","iopub.execute_input":"2021-09-23T10:35:11.91458Z","iopub.status.idle":"2021-09-23T10:35:11.929346Z","shell.execute_reply.started":"2021-09-23T10:35:11.914528Z","shell.execute_reply":"2021-09-23T10:35:11.928665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nWe saw above that total charges column is object type\nHence we convert that to numerical column\nwe also see that when we replaced \" \" by \"_\" missing values here got replaced by \"_\"\n\"\"\"\n# We convert totalcharges to numerical and to ignore the errors (in our case  \"_\") we use errors='coerce'\n# Store the results back to the original column\ndf.totalcharges = pd.to_numeric(df.totalcharges, errors='coerce')\n\n#  Finally take care of the the missing values in totalcharges columns by filling up by 0.\ndf.totalcharges = df.totalcharges.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:11.930287Z","iopub.execute_input":"2021-09-23T10:35:11.931021Z","iopub.status.idle":"2021-09-23T10:35:11.944769Z","shell.execute_reply.started":"2021-09-23T10:35:11.930987Z","shell.execute_reply":"2021-09-23T10:35:11.943937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Next we convert YES/NO values in churn variable to int 1/0 and store it back to original col\"\"\"\ndf.churn = (df.churn == 'yes').astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:11.946219Z","iopub.execute_input":"2021-09-23T10:35:11.946708Z","iopub.status.idle":"2021-09-23T10:35:11.95785Z","shell.execute_reply.started":"2021-09-23T10:35:11.946661Z","shell.execute_reply":"2021-09-23T10:35:11.956367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"6\"></a>\n\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">6. Setting up the validation framework\n    \n</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"We are using sklearn train_test_split function to split the data into full_train and test set\"\"\"\nfrom sklearn.model_selection import train_test_split\n\n# Making full_train and test set\ndf_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n\n# Next making train and validation set from full_train set\ndf_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n\n# checking the number of values in datasets\nprint(\"Train_set %s:\" %len(df_train), \"Validation_set %s:\" %len(df_val), \"Test_set %s:\" %len(df_test))\n\n# Dropping indexes of these datasets\ndf_train = df_train.reset_index(drop=True)\ndf_val = df_val.reset_index(drop=True)\ndf_test = df_test.reset_index(drop=True)\n\n# Creating Dependent Variables\ny_train = df_train.churn.values\ny_val = df_val.churn.values\ny_test = df_test.churn.values\n\n# Deleting target column i.e. churn from training datasets\ndel df_train['churn']\ndel df_val['churn']\ndel df_test['churn']","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:11.959528Z","iopub.execute_input":"2021-09-23T10:35:11.960567Z","iopub.status.idle":"2021-09-23T10:35:11.999857Z","shell.execute_reply.started":"2021-09-23T10:35:11.960514Z","shell.execute_reply":"2021-09-23T10:35:11.998481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"7\"></a>\n\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">7. Exploratory Data Analysis\n    \n</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"Removing the index column\"\"\"\ndf_full_train = df_full_train.reset_index(drop=True)\n\n\"\"\"Checking for missing values\"\"\"\ndf_full_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:12.001309Z","iopub.execute_input":"2021-09-23T10:35:12.001575Z","iopub.status.idle":"2021-09-23T10:35:12.029447Z","shell.execute_reply.started":"2021-09-23T10:35:12.001546Z","shell.execute_reply":"2021-09-23T10:35:12.028667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Checking the target variable- churn, for the ratio of 0s and 1s\nalso known as Global Churn Rate\"\"\"\nprint(df_full_train['churn'].value_counts(normalize = True))\n\n\"\"\"Also means Global Churn Rate of 1s as when adding in mean only 1 will be adding.\"\"\"\nprint(df_full_train['churn'].mean())\n\n\n\"\"\"Creating Categorical and Numerical Columns\"\"\"\nuseful_features = [col for col in df_full_train.columns if col not in ['customerid', 'churn']]\ncategorical = [col for col in useful_features if df_full_train[col].dtype == 'object'] + ['seniorcitizen']\nnumerical = [col for col in useful_features if col not in categorical]","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:12.030801Z","iopub.execute_input":"2021-09-23T10:35:12.031688Z","iopub.status.idle":"2021-09-23T10:35:12.045319Z","shell.execute_reply.started":"2021-09-23T10:35:12.031655Z","shell.execute_reply":"2021-09-23T10:35:12.044131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"8.1\"></a>\n\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">8.1 Feature Importance: Churn Rate and Risk Ratio\n    \n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:15px;color:white\">1. Difference = Group Churn Rate - Global Churn Rate </div>\n\n- **If this value is less than 0 : ``More Likely  to  churn``**\n- **If this value is more than 0 : ``Less Likely  to  churn``**\n\n<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:15px;color:white\">2. Risk Ratio = Group Churn Rate / Global Churn Rate </div>\n\n- **If this value is more than 1 : ``More Likely  to  churn``**\n- **If this value is less than 1 : ``Less Likely  to  churn``**\n","metadata":{}},{"cell_type":"code","source":"# Library to use display multiple output, especially when using loops\nfrom IPython.display import display\n\n\"\"\"Calculating Global Churn Rate\"\"\"\nglobal_churn = df_full_train.churn.mean()\n\n\"\"\"Creating a for loop to display Differences and Risk Ratio for different groups\"\"\"\nfor c in categorical:\n    print(c)\n    df_group = df_full_train.groupby(c)['churn'].agg(['mean', 'count'])\n    df_group['diff'] = df_group['mean'] - global_churn\n    df_group['risk'] = df_group['mean'] / global_churn\n    display(df_group.style.background_gradient(\"bone_r\"))\n    print()\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:44:52.265448Z","iopub.execute_input":"2021-09-23T11:44:52.266436Z","iopub.status.idle":"2021-09-23T11:44:52.621753Z","shell.execute_reply.started":"2021-09-23T11:44:52.266389Z","shell.execute_reply":"2021-09-23T11:44:52.620627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"8.2\"></a>\n\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">8.2 Feature Importance: Mutual Information \n<ul>\n<li style= \"font-size:15px;font-family:cursive;color:white\";>Concept from information theory, it tells us how much we can learn about one variable if we know the value of another </li></ul>\n</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"Library for mutual Information\"\"\"\nfrom sklearn.metrics import mutual_info_score\n\n\n\"\"\"Defining a function to calculate mutaul info score and it takes only one variable\"\"\"\ndef mutual_info_churn_score(series):\n    return mutual_info_score(series, df_full_train.churn)\n\n\"\"\"Applying the above function to categorical variables\"\"\"\nmi = df_full_train[categorical].apply(mutual_info_churn_score)\nmi.sort_values(ascending = False).to_frame().reset_index().rename({'index': 'Variables', 0: 'Improtance'}, axis = 1).style.background_gradient('crest')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:12.249113Z","iopub.execute_input":"2021-09-23T10:35:12.249425Z","iopub.status.idle":"2021-09-23T10:35:12.477562Z","shell.execute_reply.started":"2021-09-23T10:35:12.249385Z","shell.execute_reply":"2021-09-23T10:35:12.476895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"8.3\"></a>\n\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">8.3 Feature Importance: Correlation\n<ul style= \"font-size:15px;font-family:cursive;color:white\">\n<li >We use Correlation to udnerstand the relation between two numeric variables.</li>\n<li>We use Correlation coefficient to quatify the realtion between two numeric variables.</li></ul>\n</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"Checking the correaltion of numerical Columns with Target variable churn\"\"\"\n\ndf_full_train[numerical].corrwith(df_full_train.churn)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:12.478544Z","iopub.execute_input":"2021-09-23T10:35:12.479255Z","iopub.status.idle":"2021-09-23T10:35:12.494156Z","shell.execute_reply.started":"2021-09-23T10:35:12.479219Z","shell.execute_reply":"2021-09-23T10:35:12.493248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Correlation matrix\"\"\"\ndf[numerical].corr()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:12.496821Z","iopub.execute_input":"2021-09-23T10:35:12.497063Z","iopub.status.idle":"2021-09-23T10:35:12.51258Z","shell.execute_reply.started":"2021-09-23T10:35:12.497036Z","shell.execute_reply":"2021-09-23T10:35:12.511447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Using heatmap\"\"\"\nsns.heatmap(df[numerical].corr(), square = True, annot = True, lw = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:12.51384Z","iopub.execute_input":"2021-09-23T10:35:12.51409Z","iopub.status.idle":"2021-09-23T10:35:12.87286Z","shell.execute_reply.started":"2021-09-23T10:35:12.514062Z","shell.execute_reply":"2021-09-23T10:35:12.872138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Checking the correlation by groups in Numeric columns\"\"\"\nprint(\"Mean Churn Rate when Tenure <= 2: \",df_full_train[df_full_train.tenure <= 2].churn.mean())\nprint(\"Mean Churn Rate when Tenure between 2 and 12: \",df_full_train[(df_full_train.tenure > 2) & (df_full_train.tenure <= 12)].churn.mean())\nprint(\"Mean Churn Rate when Tenure more than 12: \",df_full_train[df_full_train.tenure > 12].churn.mean())\nprint()\nprint(\"Mean Churn Rate when monthlycharges <= 20: \",df_full_train[df_full_train.monthlycharges <= 20].churn.mean())\nprint(\"Mean Churn Rate when monthlycharges between 20 and 50: \",df_full_train[(df_full_train.monthlycharges > 20) & (df_full_train.monthlycharges <= 50)].churn.mean())\nprint(\"Mean Churn Rate when monthlycharges more than 50: \",df_full_train[df_full_train.monthlycharges > 50].churn.mean())","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:12.874074Z","iopub.execute_input":"2021-09-23T10:35:12.874328Z","iopub.status.idle":"2021-09-23T10:35:12.902137Z","shell.execute_reply.started":"2021-09-23T10:35:12.874299Z","shell.execute_reply":"2021-09-23T10:35:12.901271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"9\"></a>\n\n<div style=\"background:#2b6684; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">9. One Hot Encoding using DictVectorizer\n    <ul style= \"font-size:15px;font-family:cursive;color:white\">\n<li ;>Takes in Dictionary and converts itno vector form. Categorical columns are converted using One Hot Encoding. Numerical Values are untouched and returned as Vectors as is.</li>\n<li >Sparsity of the matrix can be controlled by parameter sparse = False</li></ul>\n</div>","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction import DictVectorizer\n\ndv = DictVectorizer(sparse=False)                              \n\ntrain_dict = df_train[useful_features].to_dict(orient='records') # For making dict row-wise we use orient = 'records\nX_train = dv.fit_transform(train_dict)\n\nval_dict = df_val[useful_features].to_dict(orient='records') # For making dict row-wise we use orient = 'records'\nX_val = dv.transform(val_dict)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:12.903386Z","iopub.execute_input":"2021-09-23T10:35:12.903652Z","iopub.status.idle":"2021-09-23T10:35:13.245256Z","shell.execute_reply.started":"2021-09-23T10:35:12.903615Z","shell.execute_reply":"2021-09-23T10:35:13.244642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"10\"></a>\n\n<div style=\"background:#2b6684; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">10. Logistic Regression<ul style= \"font-size:15px;font-family:cursive;color:white\">\n<li >Similar to Linear Regression as both of them are linear models.</li>\n<li >Logistic Regression uses sigmoid function over the score of dot product and hence converts the results into the range of 0,1.</li>\n<li >Sigmoid Function = $\\large g(x_i) = \\Large \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-x} }  $</li>\n<li >Linear regression is straightforward to understand and explain, and can be regularized to avoid overfitting. In addition, linear models can be updated easily with new data using stochastic gradient descent.</li></ul>\n</div> ","metadata":{}},{"cell_type":"code","source":"def sigmoid(z):\n    return 1 / (1 + np.exp(-z))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:19:46.602131Z","iopub.execute_input":"2021-09-23T11:19:46.602488Z","iopub.status.idle":"2021-09-23T11:19:46.607637Z","shell.execute_reply.started":"2021-09-23T11:19:46.602452Z","shell.execute_reply":"2021-09-23T11:19:46.606767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def linear_regression(xi):\n    result = w0\n    \n    for j in range(len(w)):\n        result = result + xi[j] * w[j]\n        \n    return result\n\ndef logistic_regression(xi):\n    score = w0\n    \n    for j in range(len(w)):\n        score = score + xi[j] * w[j]\n        \n    result = sigmoid(score)\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:13.246445Z","iopub.execute_input":"2021-09-23T10:35:13.247343Z","iopub.status.idle":"2021-09-23T10:35:13.254822Z","shell.execute_reply.started":"2021-09-23T10:35:13.247296Z","shell.execute_reply":"2021-09-23T10:35:13.253955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"11\"></a>\n\n<div style=\"background:#2b6684; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">11.  Training logistic regression with Scikit-Learn<ul style= \"font-size:15px;font-family:cursive;color:white\">\n<li >Train a model with Scikit-Learn</li>\n<li >Apply it to the validation dataset</li>\n<li >Calculate the accuracy</li></ul>\n</div> ","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(solver='lbfgs')\n# solver='lbfgs' is the default solver in newer version of sklearn\n# for older versions, you need to specify it explicitly\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:35:13.255787Z","iopub.execute_input":"2021-09-23T10:35:13.256641Z","iopub.status.idle":"2021-09-23T10:35:13.434253Z","shell.execute_reply.started":"2021-09-23T10:35:13.256583Z","shell.execute_reply":"2021-09-23T10:35:13.433306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"model intercept: Bias Term (w0)\"\"\"\nprint(\"w0 = \", model.intercept_[0])\n\n\"\"\"Coeffficients: Weights (wi)\"\"\"\nprint(\"wi = \",model.coef_[0].round(3))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:38:00.589581Z","iopub.execute_input":"2021-09-23T10:38:00.589882Z","iopub.status.idle":"2021-09-23T10:38:00.596995Z","shell.execute_reply.started":"2021-09-23T10:38:00.589854Z","shell.execute_reply":"2021-09-23T10:38:00.596094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Applying the model to Validation set to predict the probability\"\"\"\ny_pred = model.predict_proba(X_val)[:, 1]\n\n\"\"\"Making churn decision using probability threshold of 0.5\"\"\"\nchurn_decision = (y_pred >= 0.5)\n\n\"\"\"Accuracy Rate: mean of correct predictions\"\"\"\n(y_val == churn_decision).mean()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:40:56.258833Z","iopub.execute_input":"2021-09-23T10:40:56.25912Z","iopub.status.idle":"2021-09-23T10:40:56.277027Z","shell.execute_reply.started":"2021-09-23T10:40:56.259093Z","shell.execute_reply":"2021-09-23T10:40:56.275636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Observe the above result in a dataset\"\"\"\ndf_pred = pd.DataFrame()\ndf_pred['probability'] = y_pred\ndf_pred['prediction'] = churn_decision.astype(int)\ndf_pred['actual'] = y_val\n\ndf_pred['correct'] = df_pred.prediction == df_pred.actual\ndisplay(df_pred)\ndisplay(\"Accuracy Rate\", df_pred['correct'].mean())","metadata":{"execution":{"iopub.status.busy":"2021-09-23T10:43:29.272138Z","iopub.execute_input":"2021-09-23T10:43:29.272443Z","iopub.status.idle":"2021-09-23T10:43:29.302136Z","shell.execute_reply.started":"2021-09-23T10:43:29.272414Z","shell.execute_reply":"2021-09-23T10:43:29.301038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"12\"></a>\n\n<div style=\"background:#2b6684; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">12.  Model interpretation\n    <ul style= \"font-size:15px;font-family:cursive;color:white\">\n<li > Look at the coefficients</li>\n<li >Train a smaller model with fewer features</li></ul>\n</div> ","metadata":{}},{"cell_type":"code","source":"\"\"\"Understanding the use of Zip function\"\"\"\na = [1, 2, 3, 4]\nb = 'abcd'\n\n\"\"\"zip() comnines the both values by position\"\"\"\ndict(zip(a, b))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:03:56.741571Z","iopub.execute_input":"2021-09-23T11:03:56.742203Z","iopub.status.idle":"2021-09-23T11:03:56.753159Z","shell.execute_reply.started":"2021-09-23T11:03:56.742146Z","shell.execute_reply":"2021-09-23T11:03:56.751902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Now using zip to combine features and their respective coefficients\"\"\"\ndict(zip(dv.get_feature_names(), model.coef_[0].round(3)))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:04:38.931168Z","iopub.execute_input":"2021-09-23T11:04:38.93229Z","iopub.status.idle":"2021-09-23T11:04:38.943078Z","shell.execute_reply.started":"2021-09-23T11:04:38.932221Z","shell.execute_reply":"2021-09-23T11:04:38.941666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Now to understand Interpretation: Let's take small subset of the variables\"\"\"\nsmall = ['contract', 'tenure', 'monthlycharges']\n\n\"\"\"Create a model on these subset of columns\"\"\"\ndf_train[small].iloc[:10].to_dict(orient='records')\n\n# Creating training and Validation set\ndicts_train_small = df_train[small].to_dict(orient='records')\ndicts_val_small = df_val[small].to_dict(orient='records')\n\n# Using dictVectorizer for OHE on categorical colums\ndv_small = DictVectorizer(sparse=False)\ndv_small.fit(dicts_train_small)\n\n# Checking the feature names to see how many new created by DictVectorizer\ndv_small.get_feature_names()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:08:33.883797Z","iopub.execute_input":"2021-09-23T11:08:33.884488Z","iopub.status.idle":"2021-09-23T11:08:33.941506Z","shell.execute_reply.started":"2021-09-23T11:08:33.884431Z","shell.execute_reply":"2021-09-23T11:08:33.940625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Creating Training set\"\"\"\nX_train_small = dv_small.transform(dicts_train_small)\n\n\"\"\"making model on Training set\"\"\"\nmodel_small = LogisticRegression(solver='lbfgs')\nmodel_small.fit(X_train_small, y_train)\n\n\"\"\"Assigning variables w0 and wi's to bias term and weights\"\"\"\nw0 = model_small.intercept_[0]\nwi = model_small.coef_[0].round(3)\n\n\"\"\"Finally zipping w0 and wi understand interpret the model prediction\"\"\"\ndict(zip(dv_small.get_feature_names(), wi.round(3)))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:12:27.139408Z","iopub.execute_input":"2021-09-23T11:12:27.139743Z","iopub.status.idle":"2021-09-23T11:12:27.25784Z","shell.execute_reply.started":"2021-09-23T11:12:27.139699Z","shell.execute_reply":"2021-09-23T11:12:27.256303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nWe are given following info about the customer:\n- Contract : Two years\n- monthly_charges : 30\n- Tenure : 24\n\nWe also know the coeff/w of:\n- Contract : two years = -0.949\n- monthlycharges = 0.027\n- tenure' = -0.036\n\nAlso bias term(w0) = -2.47\n\nBasic Interpretation: When we dont know anything about the customer, customer is less likely to churn\n\nUsing our Linear Formula: \nw0 + w1.x1 + w2.x2 + . . .\nwe get:\n\"\"\"\n\nprint(-2.47 + (-0.949) + 30 * 0.027 + 24 * (-0.036))\n\n# Finally using sigmoid function on this value will give us the Probability of customer will churn or not\nsigmoid(-3.473)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:20:52.263579Z","iopub.execute_input":"2021-09-23T11:20:52.263938Z","iopub.status.idle":"2021-09-23T11:20:52.273707Z","shell.execute_reply.started":"2021-09-23T11:20:52.263908Z","shell.execute_reply":"2021-09-23T11:20:52.272938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"13\"></a>\n\n<div style=\"background:#2b6684; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">13.  Using the model\n</div> ","metadata":{}},{"cell_type":"code","source":"\"\"\"Now we train the model on the full_train set and predict on test set\"\"\"\n\ndicts_full_train = df_full_train[categorical + numerical].to_dict(orient='records')\n\ndv = DictVectorizer(sparse=False)\nX_full_train = dv.fit_transform(dicts_full_train)\n\ny_full_train = df_full_train.churn.values\n\nmodel = LogisticRegression(solver='lbfgs')\nmodel.fit(X_full_train, y_full_train)\n\ndicts_test = df_test[categorical + numerical].to_dict(orient='records')\n\nX_test = dv.transform(dicts_test)\n\ny_pred = model.predict_proba(X_test)[:, 1]\n\nchurn_decision = (y_pred >= 0.5)\n\nprint(\"Accuracy on Test Set: \", (churn_decision == y_test).mean())","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:33:09.570515Z","iopub.execute_input":"2021-09-23T11:33:09.571577Z","iopub.status.idle":"2021-09-23T11:33:10.181983Z","shell.execute_reply.started":"2021-09-23T11:33:09.571521Z","shell.execute_reply":"2021-09-23T11:33:10.180946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Predicting on an individual customer to check how the model behaves\"\"\"\ncustomer = dicts_test[-1]\ncustomer","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:33:44.492814Z","iopub.execute_input":"2021-09-23T11:33:44.493168Z","iopub.status.idle":"2021-09-23T11:33:44.501083Z","shell.execute_reply.started":"2021-09-23T11:33:44.493125Z","shell.execute_reply":"2021-09-23T11:33:44.499958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_small = dv.transform([customer])\nprint(\"Predicted Probability: \",model.predict_proba(X_small)[0, 1])\nprint(\"Original Value: \",y_test[-1])","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:34:59.116566Z","iopub.execute_input":"2021-09-23T11:34:59.116992Z","iopub.status.idle":"2021-09-23T11:34:59.126656Z","shell.execute_reply.started":"2021-09-23T11:34:59.116954Z","shell.execute_reply":"2021-09-23T11:34:59.125063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"14\"></a>\n\n<div style=\"background:#2b6684; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px;color:yellow\">14.  Summary\n<ul style= \"font-size:15px;font-family:cursive;color:white\">\n<li >Feature importance - risk, mutual information, correlation</li>\n<li >One-hot encoding can be implemented with DictVectorizer</li>\n<li >Logistic regression - linear model like linear regression</li>\n<li >Output of log reg - probability</li>\n<li >Interpretation of weights is similar to linear regression</li></ul>\n</div>","metadata":{}}]}